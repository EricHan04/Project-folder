{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-24T01:36:23.800878Z",
     "start_time": "2022-10-24T01:36:19.940903Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\duchi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('max_colwidth', None)\n",
    "\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from collections import Counter\n",
    "import en_core_web_trf\n",
    "nlp = en_core_web_trf.load()\n",
    "\n",
    "import re\n",
    "\n",
    "# # Import the wordcloud library\n",
    "# from wordcloud import WordCloud\n",
    "\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "import gensim.corpora as corpora\n",
    "from pprint import pprint\n",
    "\n",
    "# from gensim.models import CoherenceModel\n",
    "# import tqdm\n",
    "\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "import pickle \n",
    "import pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-24T01:34:36.968573Z",
     "start_time": "2022-10-24T01:34:36.957603Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#functions\n",
    "\n",
    "def cleanText(text):\n",
    "#     text = re.sub(r'@[A-Za-z0-9:_]+', '', text)  # remove @mensions\n",
    "    text = re.sub(r'#', ' ', text)  # remove '#'\n",
    "    text = re.sub(r'&amp;', ' ', text)\n",
    "#     text = re.sub(r'RT[\\s]+', '', text)  # remove RT\n",
    "    text = re.sub(r'https?:\\/\\/\\S+', ' ', text)  # remove the hyper link\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    text = emoji_pattern.sub(r'', text) # remove emoji\n",
    "    text = re.sub(r'[.,\"\\'?:!;]', ' ', text)  # remove punctions\n",
    "    text = re.sub(u\"([^\\u0041-\\u005a\\u0061-\\u007a\\u0020\\u0027])\", ' ', text)  # just keep words, spaces and single quote\n",
    "    return text\n",
    "\n",
    "def join_string(file):\n",
    "    text = str()\n",
    "    for line in file:\n",
    "        #     print(line)\n",
    "        if line.find('Word count') != -1:\n",
    "            pass\n",
    "        elif line.find('CREDIT:') != -1:\n",
    "            pass\n",
    "        else:\n",
    "            text = text + \" \" + line.strip('\\n ')\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# join the proquest article text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-24T01:36:04.473851Z",
     "start_time": "2022-10-24T01:36:00.577197Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100, 200, 300, 400, 500, 600, 700, 800, 900, 1000]\n"
     ]
    }
   ],
   "source": [
    "#join the proquest article text\n",
    "\n",
    "pq_link = pd.read_csv(\n",
    "    r'C:\\Users\\duchi\\OneDrive - University of South Australia\\Python\\3 webscrapping\\2 newspaper\\proquest_link.csv',\n",
    "    encoding='iso-8859-1')\n",
    "pq_link.columns = ['link','company']\n",
    "\n",
    "l1 = np.arange(1, 11)\n",
    "l1 = [x * 100 for x in l1]\n",
    "print(l1)\n",
    "detail = pd.DataFrame()\n",
    "for fix in l1:\n",
    "    temp = pd.read_csv(\n",
    "        r'C:\\Users\\duchi\\OneDrive - University of South Australia\\Python\\3 webscrapping\\2 newspaper\\news_{}.csv'\n",
    "        .format(fix),\n",
    "        encoding='iso-8859-1')\n",
    "    detail = pd.concat([detail,temp], ignore_index=True)\n",
    "    \n",
    "pq_link = pd.merge(pq_link,detail, how='left', on=['link','company'])\n",
    "\n",
    "l2 = []\n",
    "for i in range(0, 983):\n",
    "    \n",
    "    file = open(\n",
    "        r'C:\\Users\\duchi\\OneDrive - University of South Australia\\Python\\3 webscrapping\\2 newspaper\\proquest text\\{}.txt'\n",
    "        .format(i),\n",
    "        encoding=\"utf8\")\n",
    "    \n",
    "    l2.append(join_string(file))\n",
    "    \n",
    "pq_link['text'] = l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-24T01:36:05.728607Z",
     "start_time": "2022-10-24T01:36:05.721592Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# pq_link.to_excel(r'C:\\Users\\duchi\\OneDrive - University of South Australia\\Python\\3 webscrapping\\3 summary\\proquest_news tech summary.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-24T02:27:35.567609Z",
     "start_time": "2022-10-24T02:27:34.539400Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opentute\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"> Russian-born model turned designer <mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">Katya Komarova<span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span></mark> has become a global sensation – and she tells <mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">Gordon Knight<span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span></mark> about her show at next month’s Adelaide Fashion Festival MUSCOVITE MODEL I was born and raised in Moscow. Both my mother and father are trained engineers – though my mum never really worked as an engineer, she loved music and she dedicated most of her life to it. But as a child I dreamt of becoming a model and about 15 years ago I started my career in the fashion world as a model – but I wasn’t really planning to be a designer. THAI TEACHER During one of my modelling travels I took a break in Thailand and I met a leather artisan on Koh Tao island. He taught me how to make a leather bracelet in his studio and that was the beginning. I decided to start making things out of leather, so I came home to Russia, cut up my mother’s boots and made a clutch for my girlfriend. DIRTY ABOUT BOOTS? Mum was fine about her boots – they were very old. HEADING SOUTH I met my husband while on holiday in Australia a few days before I had to go back to Russia. Just a month and a half after we met he visited me in Russia to discuss whether I could possibly move to Australia. I moved here about five years ago. PIECE MAKER I’m exploring the versatility of having fewer pieces – wearing the same stuff but styling them with different leather corsets. It’s the same for handbags – you can have one handbag but it can be a daywear bag, an evening bag, a cross-body bag for running around markets. I can really see that there are a lot of core pieces that every woman has in her wardrobe and they come to life when you put accessories with them. NOT JUST ACCESSORIES I can’t open all the secrets, but my Adelaide Fashion Festival show models will be dressed head to toe with <mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">Katya Komarova<span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span></mark>. In my show there will be a lot of basics styled with a lot of accessories. BOUND TO BE BIG Some of my corsets have become best sellers and were seen at New York Fashion Week and in fashion magazines such as <mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">Vogue<span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span></mark> and <mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">Elle<span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span></mark>. (Corsetry) is something I love doing and experimenting with because even a boring, oversized jumper can become a statement piece – if you add a corset. WASTE NOT I feel quite responsible for the fashion industry’s mass production and wastage. I don’t want to overproduce, so what I came up with is an innovative design that enables me to maintain my stock very efficiently. I laser cut all of my leather here in Adelaide and it actually doesn’t take long to assemble those bags – that’s why the price is quite affordable. I’m using very high-end expensive Italian leather. But I minimise the cost of production. The bucket bags are taking off. They’re best-selling pieces. NO TIME TO SLOUCH I don’t have much time to relax because I also run another business (with husband <mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">Travis Clapp<span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span></mark>) – it’s an e-learning software company called Opentute. And as part of that software project I’ve started building another product using the same tech. It’s going to be filling the gap of skills, how to break into the fashion industry. I am also still modelling but not this season. I decided not to model at Adelaide Fashion Festival because this year it’s getting a bit too much. I’m planning an overseas trade show in Asia and this will be my third Adelaide Fashion Festival – I debuted in 2016. I feel very proud about it all – and very pleased. Adelaide Fashion Festival, October 17-21, adelaidefashionfestival.com.au, katyakomarova.com, opentute.com</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 516\n",
    "print(pq_link['company'].loc[i])\n",
    "text = pq_link['text'].loc[i]\n",
    "\n",
    "doc = nlp(text)\n",
    "filter = {'ents':['ORG','PERSON']}\n",
    "displacy.render(doc, style=\"ent\", jupyter=True, minify= True, options = filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-20T23:31:48.577890Z",
     "start_time": "2022-10-20T23:31:48.240863Z"
    }
   },
   "outputs": [],
   "source": [
    "#clean the text\n",
    "pq_link['processed_text'] = pq_link['text'].map(lambda x: cleanText(x))\n",
    "pq_link['processed_text'] = pq_link['processed_text'].map(lambda x: x.lower())\n",
    "\n",
    "long_string = ','.join(list(pq_link['processed_text'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-20T23:31:48.582542Z",
     "start_time": "2022-10-20T23:31:48.579830Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #generate wordcloud\n",
    "# wordcloud = WordCloud(background_color=\"white\", max_words=5000, contour_width=3, contour_color='steelblue')\n",
    "# wordcloud.generate(long_string)\n",
    "# wordcloud.to_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-20T23:31:48.659958Z",
     "start_time": "2022-10-20T23:31:48.585327Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the\n"
     ]
    }
   ],
   "source": [
    "#some more function\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use'])\n",
    "\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        # deacc=True removes punctuations\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out\n",
    "\n",
    "# data = pq_link['processed_text'].values.tolist()\n",
    "# data_words = list(sent_to_words(data))\n",
    "\n",
    "data = pq_link['processed_text'].loc[97]\n",
    "data_words = list(gensim.utils.simple_preprocess(str(data), deacc=True))\n",
    "# remove stop words\n",
    "data_words_nostops = remove_stopwords(data_words)\n",
    "print(data_words[:1][0][:30])\n",
    "\n",
    "#for LDA analysis\n",
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)\n",
    "# Faster way to get a sentence clubbed as a trigram/bigram\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-20T23:31:53.357059Z",
     "start_time": "2022-10-20T23:31:48.663600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[]]\n"
     ]
    }
   ],
   "source": [
    "# Form Bigrams\n",
    "data_words_bigrams = make_trigrams(data_words_nostops)\n",
    "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
    "# nlp = spacy.load(\"en_core_web_lg\")\n",
    "nlp = spacy.load(\"en_core_web_lg\", disable=['parser', 'ner'])\n",
    "# Do lemmatization keeping only noun, adj, vb, adv\n",
    "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "print(data_lemmatized[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-20T23:31:53.391800Z",
     "start_time": "2022-10-20T23:31:53.362642Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[]]\n"
     ]
    }
   ],
   "source": [
    "#Data Transformation: Corpus and Dictionary\n",
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_lemmatized)\n",
    "# Create Corpus\n",
    "texts = data_lemmatized\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "# View\n",
    "print(corpus[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-20T23:31:53.428701Z",
     "start_time": "2022-10-20T23:31:53.419661Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Build LDA model\n",
    "# lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "#                                        id2word=id2word,\n",
    "#                                        num_topics=5, \n",
    "#                                        random_state=100,\n",
    "#                                        chunksize=100,\n",
    "#                                        passes=10,\n",
    "#                                        per_word_topics=True,\n",
    "#                                        workers=3)\n",
    "\n",
    "\n",
    "# # Print the Keyword in the 10 topics\n",
    "# pprint(lda_model.print_topics())\n",
    "# doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-20T23:31:53.987581Z",
     "start_time": "2022-10-20T23:31:53.434780Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lda_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-bb79aff788ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtop_words_per_topic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlda_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_topics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtop_words_per_topic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlda_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow_topic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlda_model_100\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_words_per_topic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Topic'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Word'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'P'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lda_model' is not defined"
     ]
    }
   ],
   "source": [
    "top_words_per_topic = []\n",
    "for t in range(lda_model.num_topics):\n",
    "    top_words_per_topic.extend([(t, ) + x for x in lda_model.show_topic(t, topn = 100)])\n",
    "\n",
    "lda_model_100 = pd.DataFrame(top_words_per_topic, columns=['Topic', 'Word', 'P'])\n",
    "\n",
    "lda_model_100[['Topic','Word']].groupby('Topic')['Word'].unique().reset_index().to_csv('test.csv', index=None, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-20T23:31:53.989936Z",
     "start_time": "2022-10-20T23:31:42.747Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Compute Coherence Score\n",
    "# coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "# coherence_lda = coherence_model_lda.get_coherence()\n",
    "# print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-20T23:31:53.991495Z",
     "start_time": "2022-10-20T23:31:42.749Z"
    }
   },
   "outputs": [],
   "source": [
    "# # supporting function\n",
    "# def compute_coherence_values(corpus, dictionary, k, a, b):\n",
    "    \n",
    "#     lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "#                                            id2word=dictionary,\n",
    "#                                            num_topics=k, \n",
    "#                                            random_state=100,\n",
    "#                                            chunksize=100,\n",
    "#                                            passes=10,\n",
    "#                                            alpha=a,\n",
    "#                                            eta=b)\n",
    "    \n",
    "#     coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "    \n",
    "#     return coherence_model_lda.get_coherence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-20T23:31:53.992627Z",
     "start_time": "2022-10-20T23:31:42.752Z"
    }
   },
   "outputs": [],
   "source": [
    "# grid = {}\n",
    "# grid['Validation_Set'] = {}\n",
    "# # Topics range\n",
    "# min_topics = 2\n",
    "# max_topics = 11\n",
    "# step_size = 1\n",
    "# topics_range = range(min_topics, max_topics, step_size)\n",
    "# # Alpha parameter\n",
    "# alpha = list(np.arange(0.01, 1, 0.3))\n",
    "# alpha.append('symmetric')\n",
    "# alpha.append('asymmetric')\n",
    "# # Beta parameter\n",
    "# beta = list(np.arange(0.01, 1, 0.3))\n",
    "# beta.append('symmetric')\n",
    "# # Validation sets\n",
    "# num_of_docs = len(corpus)\n",
    "# corpus_sets = [# gensim.utils.ClippedCorpus(corpus, num_of_docs*0.25), \n",
    "#                # gensim.utils.ClippedCorpus(corpus, num_of_docs*0.5), \n",
    "#                gensim.utils.ClippedCorpus(corpus, int(num_of_docs*0.75)), \n",
    "#                corpus]\n",
    "# corpus_title = ['75% Corpus', '100% Corpus']\n",
    "# model_results = {'Validation_Set': [],\n",
    "#                  'Topics': [],\n",
    "#                  'Alpha': [],\n",
    "#                  'Beta': [],\n",
    "#                  'Coherence': []\n",
    "#                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-20T23:31:53.994285Z",
     "start_time": "2022-10-20T23:31:42.755Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# # Can take a long time to run\n",
    "# if 1 == 1:\n",
    "#     pbar = tqdm.tqdm(total=540)\n",
    "    \n",
    "#     # iterate through validation corpuses\n",
    "#     for i in range(len(corpus_sets)):\n",
    "#         # iterate through number of topics\n",
    "#         for k in topics_range:\n",
    "#             # iterate through alpha values\n",
    "#             for a in alpha:\n",
    "#                 # iterare through beta values\n",
    "#                 for b in beta:\n",
    "#                     # get the coherence score for the given parameters\n",
    "#                     cv = compute_coherence_values(corpus=corpus_sets[i], dictionary=id2word, \n",
    "#                                                   k=k, a=a, b=b)\n",
    "#                     # Save the model results\n",
    "#                     model_results['Validation_Set'].append(corpus_title[i])\n",
    "#                     model_results['Topics'].append(k)\n",
    "#                     model_results['Alpha'].append(a)\n",
    "#                     model_results['Beta'].append(b)\n",
    "#                     model_results['Coherence'].append(cv)\n",
    "                    \n",
    "#                     pbar.update(1)\n",
    "#     pd.DataFrame(model_results).to_csv('lda_tuning_results.csv', index=False)\n",
    "#     pbar.close()\n",
    "\n",
    "# model_results = pd.read_csv('lda_tuning_results.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-20T23:31:53.995821Z",
     "start_time": "2022-10-20T23:31:42.759Z"
    }
   },
   "outputs": [],
   "source": [
    "#Final Model\n",
    "\n",
    "lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=100, \n",
    "                                           random_state=100,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha=0.01,\n",
    "                                           eta=0.9,\n",
    "                                           workers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-20T23:31:53.996938Z",
     "start_time": "2022-10-20T23:31:42.762Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Visualize Topics\n",
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "LDAvis_prepared = pyLDAvis.gensim_models.prepare(lda_model, corpus, id2word)\n",
    "LDAvis_prepared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
