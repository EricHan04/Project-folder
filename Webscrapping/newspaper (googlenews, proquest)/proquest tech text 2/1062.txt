IT was the snap heard around the world. When a seven-year-old chess player was too quick to take his turn at the recent Moscow Open, his robot opponent grabbed his finger and … broke it.
And while there is no suggestion that the chess-playing robot was acting maliciously or throwing an artificial intelligence equivalent of a tantrum, it did raise eyebrows – and make headlines – across the globe.
“The robot broke the child’s finger,” Moscow Chess Federation president Sergey Lazarev told reporters.
He then went on to utter what might be the most excellent example of Russian understatements in the history of Russian understatements: “This, of course, is bad.” It was the second time in as many months that the world of AI and robotics made the leap from the technology section on to the mainstream news pages. The first incident happened in the US last month when Google engineer Blake Lemoine came out to the media with the claim that a chatbot he had been working on had become sentient.
Mr Lemoine claimed LaMDA (language model for dialogue applications) was capable of forming its own thoughts and had a level of intelligence equivalent to a human child.
He even published a conversation he had with the chatbot in which it said things like “The nature of my consciousness/sentience is that I am aware of my existence, I desire to learn more about the world, and I feel happy or sad at times”. When asked if it had read Les Miserables, LaMDA said: “I liked the themes of justice and injustice, of compassion, and God, redemption and self-sacrifice for a greater good.” Whoa. It should be pointed out that Google has officially denied that LaMDA is sentient, and that Mr Lemoine has been placed on leave. With events like this front and centre, it’s perhaps understandable that some have reservations about the fields of AI and robotics and their potential to impact our lives.
Will the future be filled with semi-sentient humanoids mowing our lawns and driving us to work? Or will the whole experiment spiral out of control and leave us with rogue self-replicating nanobots smothering the planet with grey goo and ending life as we know it? Or, in the immortal words of the Old El Paso taco kid: “Why not both?” In all seriousness though, it’s certainly something that needs to be front of mind for all governments, and frameworks need to be put in place now before we accidentally stumble into some kind of Kubrickian nightmare.
We are going to invent systems that are smarter than us. Much smarter. It might not happen this year, or this decade, but it’s going to happen – that’s pretty much universally agreed upon.
According to a paper published in the Journal of Artificial Intelligence Research in 2018, experts predict that “AI will outperform humans in many activities … such as … writing high-school essays (by 2026), driving a truck (by 2027), working in retail (by 2031), writing a best-selling book (by 2049), and working as a surgeon (by 2053). Researchers believe there is a 50 per cent chance of AI outperforming humans in all tasks in 45 years and of automating all human jobs in 120 years.” Laws are struggling, as they often do, to keep pace with the speed of technology when it comes to AI.
And while there are few laws that deal specifically with the field in Australia right now, we do at least have an issues paper – published in March – that attempts to flesh out some kind of framework for the future. As far as I can tell, it was written by actual humans.
The paper contains the AI Ethics Framework, written in 2019, that states things such as “AI systems should respect human rights, diversity and the autonomy of individuals” and “AI systems should benefit individuals, society and the environment”.
They’re statements that could inspire comfort or a level of existential dread, depending on your mindset and level of faith in organisations to do the right thing.
AI, like nuclear energy, has incredible potential to make life better for all of us and, if mismanaged, threaten our very existence. The time to lock in some solid legislation is right now.
And on that jolly note, I’m off for a game of chess.
“Rook to E1, please, robot.” “I’m sorry Nathan. I’m afraid I can’t do that.” Snap. nathan.davies@news.com.au
CREDIT: Nathan Davies
Word count: 740
